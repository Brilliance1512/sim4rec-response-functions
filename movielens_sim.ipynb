{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4ca285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syudosaev/anaconda3/envs/sim4rec/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/09 09:43:18 WARN Utils: Your hostname, ecs-syudosaev-big resolves to a loopback address: 127.0.1.1; using 10.11.12.124 instead (on interface eth0)\n",
      "24/04/09 09:43:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/09 09:43:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/09 09:43:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, PCA\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as sf\n",
    "import pyspark.sql.types as st\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes, FMClassifier\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sim4rec.modules import Simulator\n",
    "\n",
    "from replay.metrics import NDCG, Precision, RocAuc, Metric\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "from replay.data_preparator import Indexer\n",
    "\n",
    "from sim4rec.utils import pandas_to_spark, VectorElementExtractor\n",
    "from sim4rec.modules import RealDataGenerator, SDVDataGenerator\n",
    "from sim4rec.modules import evaluate_synthetic, EvaluateMetrics\n",
    "from sim4rec.response import ParametricResponseFunction, BernoulliResponse, NoiseResponse\n",
    "\n",
    "from replay.models import UCB, ItemKNN\n",
    "from replay.models import RandomRec\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName('simulator_movielens')\\\n",
    "    .master('local[*]')\\\n",
    "    .config('spark.sql.shuffle.partitions', '192')\\\n",
    "    .config('spark.default.parallelism', '192')\\\n",
    "    .config('spark.driver.extraJavaOptions', '-XX:+UseG1GC')\\\n",
    "    .config('spark.executor.extraJavaOptions', '-XX:+UseG1GC')\\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', '-1')\\\n",
    "    .config('spark.driver.memory', '256g')\\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "def calc_metric(response_df):\n",
    "    return response_df.groupBy(\"user_idx\").agg(sf.sum(\"response\").alias(\"num_positive\")).select(sf.mean(\"num_positive\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cafd3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=================================================>   (181 + 11) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "USER_PREFIX = 'user_'\n",
    "ITEM_PREFIX = 'item_'\n",
    "\n",
    "USER_SCHEMA = st.StructType(\n",
    "    [st.StructField('user_idx', st.IntegerType())] +\\\n",
    "    [st.StructField(f'genre{i}', st.DoubleType()) for i in range(19)] +\\\n",
    "    [st.StructField('rating_avg', st.DoubleType())] +\\\n",
    "    [st.StructField(f'w2v_{i}', st.DoubleType()) for i in range(300)]\n",
    ")\n",
    "ITEM_SCHEMA = st.StructType(\n",
    "    [st.StructField('item_idx', st.IntegerType())] +\\\n",
    "    [st.StructField('year', st.IntegerType())] +\\\n",
    "    [st.StructField('rating_avg', st.DoubleType())] +\\\n",
    "    [st.StructField(f'genre{i}', st.DoubleType()) for i in range(19)] +\\\n",
    "    [st.StructField(f'w2v_{i}', st.DoubleType()) for i in range(300)]\n",
    ")\n",
    "LOG_SCHEMA = st.StructType([\n",
    "    st.StructField('user_idx', st.IntegerType()),\n",
    "    st.StructField('item_idx', st.IntegerType()),\n",
    "    st.StructField('relevance', st.DoubleType()),\n",
    "    st.StructField('timestamp', st.IntegerType())\n",
    "])\n",
    "\n",
    "users_df_train = spark.read.csv('train/users.csv', header=True, schema=USER_SCHEMA)\n",
    "items_df_train = spark.read.csv('train/items.csv', header=True, schema=ITEM_SCHEMA)\n",
    "log_df_train   = spark.read.csv('train/rating.csv', header=True, schema=LOG_SCHEMA)\n",
    "\n",
    "users_df_train = users_df_train.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "items_df_train = items_df_train.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "log_df_train = log_df_train.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "log_df_train = log_df_train.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "\n",
    "log_df_train = log_df_train.join(users_df_train, log_df_train['user_id'] == users_df_train['user_id'], 'leftsemi')\n",
    "log_df_train = log_df_train.join(items_df_train, log_df_train['item_id'] == items_df_train['item_id'], 'leftsemi')\n",
    "\n",
    "for c in users_df_train.columns[1:]:\n",
    "    users_df_train = users_df_train.withColumnRenamed(c, 'user_' + c)\n",
    "    \n",
    "for c in items_df_train.columns[1:]:\n",
    "    items_df_train = items_df_train.withColumnRenamed(c, 'item_' + c)\n",
    "\n",
    "log_df_train = log_df_train.withColumn(\n",
    "    'relevance', sf.when(sf.col('relevance') > 3, 1).otherwise(0))\n",
    "\n",
    "users_df_train = users_df_train.cache()\n",
    "items_df_train = items_df_train.cache()\n",
    "log_df_train = log_df_train.cache()\n",
    "\n",
    "print(users_df_train.count())\n",
    "print(items_df_train.count())\n",
    "print(log_df_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78197e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106573\n",
      "27278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:====================================================> (186 + 6) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users_df_val = spark.read.csv('val/users.csv', header=True, schema=USER_SCHEMA)\n",
    "items_df_val = spark.read.csv('val/items.csv', header=True, schema=ITEM_SCHEMA)\n",
    "log_df_val   = spark.read.csv('val/rating.csv', header=True, schema=LOG_SCHEMA)\n",
    "\n",
    "users_df_val = users_df_val.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "items_df_val = items_df_val.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "log_df_val = log_df_val.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "log_df_val = log_df_val.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "\n",
    "log_df_val = log_df_val.join(users_df_val, log_df_val['user_id'] == users_df_val['user_id'], 'leftsemi')\n",
    "log_df_val = log_df_val.join(items_df_val, log_df_val['item_id'] == items_df_val['item_id'], 'leftsemi')\n",
    "\n",
    "for c in users_df_val.columns[1:]:\n",
    "    users_df_val = users_df_val.withColumnRenamed(c, 'user_' + c)\n",
    "\n",
    "for c in items_df_val.columns[1:]:\n",
    "    items_df_val = items_df_val.withColumnRenamed(c, 'item_' + c)\n",
    "\n",
    "log_df_val = log_df_val.withColumn(\n",
    "    'relevance', sf.when(sf.col('relevance') > 3, 1).otherwise(0))\n",
    "\n",
    "users_df_val = users_df_val.cache()\n",
    "items_df_val = items_df_val.cache()\n",
    "log_df_val = log_df_val.cache()\n",
    "\n",
    "print(users_df_val.count())\n",
    "print(items_df_val.count())\n",
    "print(log_df_val.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f45aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:======================================>              (138 + 54) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users_df_test = spark.read.csv('test/users.csv', header=True, schema=USER_SCHEMA)\n",
    "items_df_test = spark.read.csv('test/items.csv', header=True, schema=ITEM_SCHEMA)\n",
    "log_df_test   = spark.read.csv('test/rating.csv', header=True, schema=LOG_SCHEMA)\n",
    "\n",
    "users_df_test = users_df_test.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "items_df_test = items_df_test.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "log_df_test = log_df_test.withColumnRenamed(\"user_idx\", \"user_id\")\n",
    "log_df_test = log_df_test.withColumnRenamed(\"item_idx\", \"item_id\")\n",
    "\n",
    "log_df_test = log_df_test.join(users_df_test, log_df_test['user_id'] == users_df_test['user_id'], 'leftsemi')\n",
    "log_df_test = log_df_test.join(items_df_test, log_df_test['item_id'] == items_df_test['item_id'], 'leftsemi')\n",
    "\n",
    "log_df_test = log_df_test.withColumn(\n",
    "    'relevance', sf.when(sf.col('relevance') > 3, 1).otherwise(0))\n",
    "\n",
    "log_df_test = log_df_test.cache()\n",
    "\n",
    "print(log_df_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484ff229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9216818424353502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va = VectorAssembler(\n",
    "    inputCols=users_df_train.columns[1:],\n",
    "    outputCol='features'\n",
    ")\n",
    "pca = PCA(k=9, inputCol=\"features\")\n",
    "pca.setOutputCol(\"pca_features\")\n",
    "model = pca.fit(va.transform(users_df_train))\n",
    "sum(model.explainedVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e89c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_users = model.transform(va.transform(users_df_train)).select(['user_id', 'pca_features'])\n",
    "pca_users_val = model.transform(va.transform(users_df_val)).select(['user_id', 'pca_features'])\n",
    "\n",
    "pca_users = (pca_users.withColumn('user_feature', vector_to_array('pca_features'))).select(['user_id'] + [col('user_feature')[i] for i in range(9)])\n",
    "pca_users_val = (pca_users_val.withColumn('user_feature', vector_to_array('pca_features'))).select(['user_id'] + [col('user_feature')[i] for i in range(9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75b120",
   "metadata": {},
   "source": [
    "# Обучение генератора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f3d9e",
   "metadata": {},
   "source": [
    "Также в ноутбуке movielens_embeddings.ipynb был сделан вывод о том, что модель генерации GaussianCopula является наиболее подходящей в случае датасета MovieLens и эмбеддингов на основе PCA. Поэтому здесь будет использована именно эта модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa6eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "574910"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_generator = RealDataGenerator(label='items_real', seed=1234)\n",
    "\n",
    "users_generator = SDVDataGenerator(\n",
    "    label='synth',\n",
    "    id_column_name='user_id',\n",
    "    model_name='gaussiancopula',\n",
    "    parallelization_level=4,\n",
    "    device_name='cpu',\n",
    "    seed=1234\n",
    ")\n",
    "\n",
    "users_generator.fit(pca_users.drop('user_id'))\n",
    "items_generator.fit(items_df_train)\n",
    "\n",
    "real_users = pca_users.sample(0.12)\n",
    "syn_users = users_generator.generate(real_users.count())\n",
    "_ = items_generator.generate(items_df_train.select('item_id').distinct().count())\n",
    "\n",
    "train_df = log_df_val.join(pca_users, 'user_id', 'left')\\\n",
    "                     .join(items_df_train, 'item_id', 'left')\\\n",
    "                     .drop('timestamp')\n",
    "train_df = train_df.na.drop()\n",
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7854769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89829"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_svd = spark.read.csv('item_svd.csv', header=True, inferSchema=True)\n",
    "user_svd = spark.read.csv('user_svd.csv', header=True, inferSchema=True)\n",
    "\n",
    "train_df = train_df.join(item_svd, on='item_id', how='inner')\n",
    "train_df = train_df.join(user_svd, on='user_id', how='inner')\n",
    "\n",
    "test_df = log_df_test.join(pca_users_val, 'user_id', 'left')\\\n",
    "                     .join(items_df_val, 'item_id', 'left')\\\n",
    "                     .drop('timestamp')\n",
    "test_df = test_df.na.drop()\n",
    "\n",
    "test_df = test_df.join(item_svd, on='item_id', how='inner')\n",
    "test_df = test_df.join(user_svd, on='user_id', how='inner')\n",
    "\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dcc346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012237457481182967\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 792:=========================================>            (71 + 22) / 93]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007789317893380107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(train_df.count())\n",
    "print(train_df.select('user_id').distinct().count())\n",
    "print(train_df.select('item_id').distinct().count())\n",
    "print(train_df.count() / (train_df.select('user_id').distinct().count() * train_df.select('item_id').distinct().count()))\n",
    "print()\n",
    "\n",
    "print(test_df.count())\n",
    "print(test_df.select('user_id').distinct().count())\n",
    "print(test_df.select('item_id').distinct().count())\n",
    "print(test_df.count() / (test_df.select('user_id').distinct().count() * test_df.select('item_id').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73f981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2153:=====================================================>(87 + 1) / 88]]]]\r"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(\n",
    "    inputCols=pca_users.columns[1:] + items_df_train.columns[1:],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "fm = FMClassifier(\n",
    "    featuresCol='features',\n",
    "    labelCol='relevance',\n",
    "    probabilityCol='proba'\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol='features',\n",
    "    labelCol='relevance',\n",
    "    probabilityCol='proba'\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol='features',\n",
    "    labelCol='relevance',\n",
    "    probabilityCol='proba'\n",
    ")\n",
    "\n",
    "lr_model = lr.fit(va.transform(train_df))\n",
    "rf_model = rf.fit(va.transform(train_df))\n",
    "fm_model = fm.fit(va.transform(train_df))\n",
    "vee = VectorElementExtractor(inputCol='proba', outputCol='scores', index=1)\n",
    "mc = ParametricResponseFunction(inputCols=['scores'], outputCol='__pr', weights=[0.25])\n",
    "br = BernoulliResponse(inputCol='__pr', outputCol='response', seed=1234)\n",
    "pipeline_lr = PipelineModel(stages=[va, lr_model, vee, mc, br])\n",
    "pipeline_rf = PipelineModel(stages=[va, rf_model, vee, mc, br])\n",
    "pipeline_fm = PipelineModel(stages=[va, fm_model, vee, mc, br])\n",
    "\n",
    "noise_resp = NoiseResponse(mu=0.5, sigma=0.2, outputCol='__noise')\n",
    "br = BernoulliResponse(inputCol='__noise', outputCol='response')\n",
    "pipeline_rand = PipelineModel(stages=[noise_resp, br])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5000a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (baseline): 0.722652072451\n",
      "Precision (baseline): 0.6595070712780113\n",
      "Recall (baseline): 0.9842190355686771\n",
      "Accuracy (baseline): 0.6681138607799263\n",
      "F1 (baseline): 0.7897902344438569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (classificator): 0.7605809344563693\n",
      "Precision (classificator): 0.7461095100864553\n",
      "Recall (classificator): 0.8644559257697174\n",
      "Accuracy (classificator): 0.7277939195582718\n",
      "F1 (classificator): 0.8009345946562026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2267:========================================>          (153 + 38) / 191]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (classificator): 0.7233617927263982\n",
      "Precision (classificator): 0.680325600120779\n",
      "Recall (classificator): 0.9502846900042177\n",
      "Accuracy (classificator): 0.6856471740751873\n",
      "F1 (classificator): 0.7929583247793061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_baseline(test_df):\n",
    "    test_df = test_df.toPandas()\n",
    "    test_df['baseline'] = (test_df['item_rating_avg']-test_df['item_rating_avg'].min())/(test_df['item_rating_avg'].max()-test_df['item_rating_avg'].min())\n",
    "    test_df['baseline_bin'] = np.where(test_df['baseline'] > 0.5, 1, 0) \n",
    "    print(f\"ROC AUC (baseline): {roc_auc_score(test_df.relevance, test_df.baseline)}\")\n",
    "    print(f\"Precision (baseline): {precision_score(test_df.relevance, test_df.baseline_bin)}\")\n",
    "    print(f\"Recall (baseline): {recall_score(test_df.relevance, test_df.baseline_bin)}\")\n",
    "    print(f\"Accuracy (baseline): {accuracy_score(test_df.relevance, test_df.baseline_bin)}\")\n",
    "    print(f\"F1 (baseline): {f1_score(test_df.relevance, test_df.baseline_bin)}\")\n",
    "    print()\n",
    "\n",
    "def assess_models(model, test_df):\n",
    "    pred_df = model.transform(test_df).select(\"user_id\", \"item_id\", \"relevance\", \"scores\").toPandas()\n",
    "    pred_df['response_bin'] = np.where(pred_df['scores'] > 0.5, 1, 0)\n",
    "    print(f\"ROC AUC (classificator): {roc_auc_score(pred_df.relevance, pred_df.scores)}\")\n",
    "    print(f\"Precision (classificator): {precision_score(pred_df.relevance, pred_df.response_bin)}\")\n",
    "    print(f\"Recall (classificator): {recall_score(pred_df.relevance, pred_df.response_bin)}\")\n",
    "    print(f\"Accuracy (classificator): {accuracy_score(pred_df.relevance, pred_df.response_bin)}\")\n",
    "    print(f\"F1 (classificator): {f1_score(pred_df.relevance, pred_df.response_bin)}\")\n",
    "    print()\n",
    "\n",
    "get_baseline(test_df)\n",
    "assess_models(pipeline_lr, test_df)\n",
    "assess_models(pipeline_rf, test_df)\n",
    "assess_models(pipeline_fm, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4fa0b",
   "metadata": {},
   "source": [
    "В качестве бейзлайна будем использовать рекомендательную систему, которая предлагает пользователю случайные предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61bd7c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = Indexer(user_col='user_id', item_col='item_id')\n",
    "indexer.fit(users=users_generator.sample(1.0), items=items_df_train)\n",
    "\n",
    "dummy_log = pandas_to_spark(pd.DataFrame({'user_id' : [1], 'item_id' : [1], 'relevance' : [0.0]}))\n",
    "\n",
    "ucb_lr = UCB()\n",
    "ucb_lr.fit(indexer.transform(dummy_log))\n",
    "\n",
    "ucb_rf = UCB()\n",
    "ucb_rf.fit(indexer.transform(dummy_log))\n",
    "\n",
    "ucb_fm = UCB()\n",
    "ucb_fm.fit(indexer.transform(dummy_log))\n",
    "\n",
    "ucb_rand = UCB()\n",
    "ucb_rand.fit(indexer.transform(dummy_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7596c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluateMetrics(\n",
    "    userKeyCol='user_id',\n",
    "    itemKeyCol='item_id',\n",
    "    predictionCol='relevance',\n",
    "    labelCol='response',\n",
    "    replay_label_filter=1.0,\n",
    "    replay_metrics={NDCG() : 5, Precision() : 5, RocAuc(): 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0688d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric(response_df):\n",
    "    return (response_df\n",
    "            .groupBy(\"user_id\").agg(sf.sum(\"response\").alias(\"num_positive\"))\n",
    "            .select(sf.mean(\"num_positive\")).collect()[0][0]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de7528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Stage 0------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def do_a_cycle(simul, model, pipeline, iteration, metrics):\n",
    "    users = simul.sample_users(0.5).dropna().cache()\n",
    "    items = simul.sample_items(0.2).dropna().cache()\n",
    "    log = simul.get_log(user_df=users)\n",
    "    log = dummy_log if log is None else log\n",
    "    log = log.cache()\n",
    "\n",
    "    recs = model.predict(\n",
    "        log=indexer.transform(log),\n",
    "        k=5,\n",
    "        users=indexer.transform(users),\n",
    "        items=indexer.transform(items),\n",
    "        filter_seen_items=True\n",
    "    )\n",
    "    recs = indexer.inverse_transform(recs).cache()\n",
    "\n",
    "    resp = simul.sample_responses(\n",
    "        recs_df=recs,\n",
    "        user_features=users,\n",
    "        item_features=items,\n",
    "        action_models=pipeline\n",
    "    ).select('user_id', 'item_id', 'relevance', 'response').cache()\n",
    "    simul.update_log(resp, iteration=iteration)\n",
    "\n",
    "    metrics.append([evaluator(resp), calc_metric(resp)])\n",
    "\n",
    "    model._clear_cache()\n",
    "    ucb_train_log = simul.log.cache()\n",
    "    model.fit(log=indexer.transform(\n",
    "        ucb_train_log.select('user_id', 'item_id', 'response').withColumnRenamed('response', 'relevance')\n",
    "    ))\n",
    "\n",
    "    log.unpersist()\n",
    "    users.unpersist()\n",
    "    items.unpersist()\n",
    "    recs.unpersist()\n",
    "    resp.unpersist()\n",
    "    ucb_train_log.unpersist()\n",
    "\n",
    "sim_lr = Simulator(users_generator, items_generator, f'checkpoints/lr', None, 'user_id', 'item_id', spark)\n",
    "sim_rf = Simulator(users_generator, items_generator, f'checkpoints/rf', None, 'user_id', 'item_id', spark)\n",
    "sim_fm = Simulator(users_generator, items_generator, f'checkpoints/fm', None, 'user_id', 'item_id', spark)\n",
    "sim_rand = Simulator(users_generator, items_generator, f'checkpoints/rand', None, 'user_id', 'item_id', spark)\n",
    "\n",
    "lr_metrics = []\n",
    "rf_metrics = []\n",
    "fm_metrics = []\n",
    "rnd_metrics = []\n",
    "\n",
    "for i in range(50):\n",
    "    print(f'------------------------Stage {i}------------------------')\n",
    "    start_iter = time.time()\n",
    "\n",
    "    do_a_cycle(sim_lr, ucb_lr, pipeline_lr, i, lr_metrics)\n",
    "    do_a_cycle(sim_rf, ucb_rf, pipeline_rf, i, rf_metrics)\n",
    "    do_a_cycle(sim_fm, ucb_fm, pipeline_fm, i, fm_metrics)\n",
    "    do_a_cycle(sim_rand, ucb_rand, pipeline_rand, i, rnd_metrics)\n",
    "    \n",
    "    end_iter = time.time()\n",
    "    print(f\"Time of {i+1} iteration: \")\n",
    "    print(end_iter - start_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
