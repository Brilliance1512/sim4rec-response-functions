{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import tqdm\n",
    "from rs_datasets import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/syudosaev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/syudosaev/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/syudosaev/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/syudosaev/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import TreebankWordTokenizer, WhitespaceTokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "words = set(nltk.corpus.words.words())\n",
    "words = set([w.lower() for w in words])\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.downloader import load\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "def title_prep(title: str) -> str:\n",
    "    title = re.sub(r'\\s+', r' ', title)\n",
    "    title = re.sub(r'($\\s+|^\\s+)', '', title)\n",
    "    title = title.lower()\n",
    "    \n",
    "    return title\n",
    "\n",
    "def extract_year(title: str) -> Optional[str]:\n",
    "    one_year = re.findall(r'\\(\\d{4}\\)', title)\n",
    "    two_years = re.findall(r'\\(\\d{4}-\\d{4}\\)', title)\n",
    "    one_year_till_today = re.findall(r'\\(\\d{4}[-â€“]\\s?\\)', title)\n",
    "    if len(one_year) == 1:\n",
    "        return int(one_year[0][1:-1])\n",
    "    \n",
    "    elif len(two_years) == 1:\n",
    "        return round((int(two_years[0][1:5]) + int(two_years[0][6:-1]))/2)\n",
    "    \n",
    "    elif len(one_year_till_today) == 1:\n",
    "        return int(one_year_till_today[0][1:5])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def genres_processing(movies: pd.DataFrame) -> pd.DataFrame:   \n",
    "    genre_lists = [set(item.split('|')).difference(set(['(no genres listed)'])) for item in movies['genres']]\n",
    "    genre_lists = pd.DataFrame(genre_lists)\n",
    "    \n",
    "    genre_dict = {token: idx for idx, token in enumerate(set(itertools.chain.from_iterable([item.split('|') \n",
    "                for item in movies['genres']])).difference(set(['(no genres listed)'])))}\n",
    "    genre_dict = pd.DataFrame(genre_dict.items())\n",
    "    genre_dict.columns = ['genre', 'index']\n",
    "    \n",
    "    dummy = np.zeros([len(movies), len(genre_dict)])\n",
    "    \n",
    "    for i in range(dummy.shape[0]):\n",
    "        for j in range(dummy.shape[1]):\n",
    "            if genre_dict['genre'][j] in list(genre_lists.iloc[i, :]):\n",
    "                dummy[i, j] = 1\n",
    "    \n",
    "    df_dummy = pd.DataFrame(dummy, columns = ['genre' + str(i) for i in range(dummy.shape[1])])\n",
    "    \n",
    "    movies_return = pd.concat([movies, df_dummy], 1)\n",
    "    return movies_return\n",
    "\n",
    "def fill_null_years(movies: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df_movies = movies.copy()\n",
    "    genres_columns = [item for item in movies.columns.tolist() if item[:5]=='genre' and item !='genres']\n",
    "    df_no_year = movies[movies.year.isna()][['item_id', *genres_columns]]\n",
    "\n",
    "    years_mean = {}\n",
    "    for i in df_no_year.index:\n",
    "    \n",
    "        row = np.asarray(df_no_year.loc[i, :][genres_columns])\n",
    "        years = []\n",
    "        for j in np.asarray(movies[['year', *genres_columns]]):\n",
    "            if np.sum(row == j[1:]) == len(genres_columns):\n",
    "                try:\n",
    "                    years.append(int(j[0]))\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        years_mean[i] = round(np.mean(years))\n",
    "    \n",
    "    for i in years_mean:\n",
    "        df_movies.loc[i, 'year'] = years_mean[i]\n",
    "    df_movies.year=df_movies.year.astype('int')\n",
    "    return df_movies\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+$\", \"\", text)\n",
    "    text = re.sub(r\"^\\s+\", \"\", text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def procces_text(text):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    text = [word for word in nltk.word_tokenize(text) if not word in stop_words]\n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    text = [word for word in text if word in words]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def string_embedding(string: str) -> np.ndarray:\n",
    "    arr = string.split(' ')\n",
    "    vec = 0\n",
    "    cnt = 0\n",
    "    for i in arr:\n",
    "        try:\n",
    "            vec += w2v_model[i]\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    if cnt == 0:\n",
    "        vec = np.zeros((300, 1))\n",
    "    else:\n",
    "        vec /= cnt\n",
    "    return vec\n",
    "\n",
    "\n",
    "def data_processing(df_movie: pd.DataFrame, \n",
    "                    df_rating: pd.DataFrame, \n",
    "                    df_tags: pd.DataFrame\n",
    ") -> List[pd.DataFrame]:\n",
    "    \n",
    "    print(\"------------------------ Movie processing ------------------------\")\n",
    "    #Extraction of the movies' years and transform genres lists to genres vector\n",
    "    df_movies_procc = df_movie.copy()\n",
    "    df_movies_procc.title = df_movies_procc.title.apply(title_prep) #title processing\n",
    "    df_movies_procc['year'] = df_movies_procc.title.apply(extract_year) #year processing\n",
    "    df_movies_procc = genres_processing(df_movies_procc) #genres processing\n",
    "    df_movies_procc = fill_null_years(df_movies_procc) #fillimg null year values\n",
    "    \n",
    "    #Creating rating_avg column \n",
    "    print(\"------------------------ Rating processing ------------------------\")\n",
    "    df_movies_procc = pd.merge(df_movies_procc, df_rating.groupby('item_id', as_index=False).rating.mean(), on='item_id', how='left')\n",
    "    df_movies_procc.rating = df_movies_procc.rating.fillna(0.0)\n",
    "    df_movies_procc = df_movies_procc.rename(columns={'rating' : 'rating_avg'})\n",
    "    df_movies_clean = df_movies_procc.drop(['title', 'genres'], axis=1)[['item_id', 'year', 'rating_avg', *['genre' + str(i) for i in range(19)]]]\n",
    "    \n",
    "    print(\"------------------------ Tags processing ------------------------\")\n",
    "    df_tags_ = df_tags.drop(df_tags[df_tags.tag.isna()].index)\n",
    "    df_movie_tags = df_tags_.sort_values(by=['item_id', 'timestamp'])[['item_id', 'tag', 'timestamp']]    \n",
    "    df_movie_tags['clean_tag'] = df_movie_tags.tag.apply(lambda x : procces_text(clean_text(x)))\n",
    "    df_movie_tags = df_movie_tags[df_movie_tags.clean_tag.str.len()!=0]\n",
    "    \n",
    "    print(\"------------------------ Tags embedding ------------------------\")\n",
    "    #tags text gathering\n",
    "    docs_movie_tags = df_movie_tags.sort_values([\"item_id\", \"timestamp\"]).groupby(\"item_id\", as_index=False).agg({\"clean_tag\":lambda x: \" \".join(x)})\n",
    "    df_movies_tags = pd.concat([docs_movie_tags.item_id, pd.DataFrame(docs_movie_tags.clean_tag.apply(string_embedding).to_list(), columns = ['w2v_' + str(i) for i in range(300)])], axis = 1)\n",
    "    df_movies_clean = pd.merge(df_movies_clean, df_movies_tags, on = \"item_id\", how = \"left\").fillna(0.0)\n",
    "    \n",
    "    print(\"------------------------ Users processing ------------------------\")\n",
    "    #users procc\n",
    "    df_users = df_rating.copy()\n",
    "    df_users = df_users.groupby(by=['user_id'], as_index=False).rating.mean().rename(columns = {'rating' : 'rating_avg'})\n",
    "    df_users_genres = pd.merge(df_movies_clean[['item_id', *df_movies_clean.columns[3:22]]], pd.merge(df_rating, df_users, on = 'user_id')[['user_id', 'item_id']],\n",
    "        on = 'item_id')\n",
    "\n",
    "    df_users_genres = df_users_genres.groupby(by = ['user_id'], as_index = False)[df_movies_clean.columns[3:22]].mean()\n",
    "    df_users_genres = pd.merge(df_users_genres, df_users, on = 'user_id')\n",
    "    df_pairs = pd.merge(df_rating, df_users, on = 'user_id')[['user_id', 'item_id']]\n",
    "    \n",
    "    print(\"------------------------ Users embedding ------------------------\")\n",
    "    users_id = []\n",
    "    vect_space = []\n",
    "    for Id in tqdm.tqdm(df_pairs.user_id.unique()):\n",
    "        movie_list = df_pairs[df_pairs.user_id == Id].item_id.tolist()\n",
    "        vect = np.asarray(df_movies_clean[df_movies_clean.item_id.isin(movie_list)][[*df_movies_clean.columns[22:]]].mean().tolist())\n",
    "        users_id.append(Id)\n",
    "        vect_space.append(vect)\n",
    "        \n",
    "    df_users_w2v = pd.DataFrame(vect_space, columns = ['w2v_' + str(i) for i in range(len(df_movies_clean.columns[22:]))])\n",
    "    df_users_w2v['user_id'] = users_id\n",
    "    df_users_clean = pd.merge(df_users_genres, df_users_w2v, on = 'user_id')\n",
    "    df_rating_clean = df_rating[['user_id', 'item_id', 'rating', 'timestamp']]\n",
    "\n",
    "    df_movies_clean = df_movies_clean.rename(columns={'item_id': 'item_idx'})\n",
    "    df_users_clean = df_users_clean.rename(columns={'user_id': 'user_idx'})\n",
    "    df_rating_clean = df_rating_clean.rename(columns={'item_id': 'item_idx', 'user_id': 'user_idx', 'rating': 'relevance'})\n",
    "    \n",
    "    return [df_movies_clean, df_users_clean, df_rating_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:59:42.041251Z",
     "start_time": "2020-02-10T15:59:09.230636Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = MovieLens(\"20m\", read_genome=True)\n",
    "df_movie = data.items\n",
    "df_rating = data.ratings\n",
    "df_tags = data.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict_movies = pd.Series(df_movie.item_id.astype(\"category\").cat.codes.values, index=df_movie.item_id).to_dict()\n",
    "cat_dict_users = pd.Series(df_rating.user_id.astype(\"category\").cat.codes.values, index=df_rating.user_id).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.item_id = df_movie.item_id.apply(lambda x: cat_dict_movies[x])\n",
    "\n",
    "df_rating.item_id = df_rating.item_id.apply(lambda x: cat_dict_movies[x])\n",
    "df_rating.user_id = df_rating.user_id.apply(lambda x: cat_dict_users[x])\n",
    "\n",
    "df_tags.item_id = df_tags.item_id.apply(lambda x: cat_dict_movies[x])\n",
    "df_tags.user_id = df_tags.user_id.apply(lambda x: cat_dict_users[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1103555886.0, 1225642317.5]\n",
      "DataFrame size: (10000132, 4)\n",
      "DataFrame size: (15000197, 4)\n",
      "DataFrame size: (20000263, 4)\n"
     ]
    }
   ],
   "source": [
    "QUANTILES = [0.5, 0.75]\n",
    "df_rating = df_rating.sort_values(by='timestamp').reset_index(drop=True)\n",
    "quantiles_values = [df_rating.timestamp.quantile(i) for i in QUANTILES]\n",
    "print(quantiles_values)\n",
    "\n",
    "df_rating_train = df_rating[df_rating.timestamp <= quantiles_values[0]]\n",
    "print(f\"DataFrame size: {df_rating_train.shape}\")\n",
    "\n",
    "df_rating_val = df_rating[(df_rating.timestamp <= quantiles_values[1])]\n",
    "print(f\"DataFrame size: {df_rating_val.shape}\")\n",
    "\n",
    "df_rating_test = df_rating.copy()\n",
    "print(f\"DataFrame size: {df_rating_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Movie processing ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77990/1545832534.py:78: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  movies_return = pd.concat([movies, df_dummy], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Rating processing ------------------------\n",
      "------------------------ Tags processing ------------------------\n",
      "------------------------ Tags embedding ------------------------\n",
      "------------------------ Users processing ------------------------\n",
      "------------------------ Users embedding ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80650/80650 [57:57<00:00, 23.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_items_train, df_users_train, df_rating_train = data_processing(df_movie, df_rating_train, df_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_train.to_csv(\"train/items.csv\", index=False)\n",
    "df_users_train.to_csv(\"train/users.csv\", index=False)\n",
    "df_rating_train.to_csv(\"train/rating.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Movie processing ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77990/1545832534.py:78: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  movies_return = pd.concat([movies, df_dummy], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Rating processing ------------------------\n",
      "------------------------ Tags processing ------------------------\n",
      "------------------------ Tags embedding ------------------------\n",
      "------------------------ Users processing ------------------------\n",
      "------------------------ Users embedding ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106573/106573 [1:27:41<00:00, 20.26it/s] \n"
     ]
    }
   ],
   "source": [
    "df_items_val, df_users_val, df_rating_val = data_processing(df_movie, df_rating_val, df_tags)\n",
    "df_rating_val = df_rating_val[df_rating_val.timestamp > quantiles_values[0]]\n",
    "df_items_val.to_csv(\"val/items.csv\", index=False)\n",
    "df_users_val.to_csv(\"val/users.csv\", index=False)\n",
    "df_rating_val.to_csv(\"val/rating.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Movie processing ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77990/1545832534.py:78: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  movies_return = pd.concat([movies, df_dummy], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Rating processing ------------------------\n",
      "------------------------ Tags processing ------------------------\n",
      "------------------------ Tags embedding ------------------------\n",
      "------------------------ Users processing ------------------------\n",
      "------------------------ Users embedding ------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138493/138493 [2:06:56<00:00, 18.18it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_items_test, df_users_test, df_rating_test = data_processing(df_movie, df_rating_test, df_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_test = df_rating_test[df_rating_test.timestamp > quantiles_values[1]]\n",
    "df_items_test.to_csv(\"test/items.csv\", index=False)\n",
    "df_users_test.to_csv(\"test/users.csv\", index=False)\n",
    "df_rating_test.to_csv(\"test/rating.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "name": "movielens_nmf.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "null"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "2e7cb45cb9e942450ddf4e57ba99c929215192dab4b3e5d4b59b5877c1991cae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
